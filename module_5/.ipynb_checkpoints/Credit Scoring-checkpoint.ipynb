{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#КРЕДИТНЫЙ СКОРИНГ\n",
    "#0. Описание проекта\n",
    "#Построение модели, предсказывающей вероятность дефолта по кредиту на основе данных по клиенту\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Импорт библиотек\n",
    "# импортируем необходимые библиотеки\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, mean_absolute_error, mean_squared_error, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
    "\n",
    "pd.set_option('display.max_rows', 50)  # показывать больше строк\n",
    "pd.set_option('display.max_columns', 50)  # показывать больше колонок\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "/kaggle/input/sf-dst-scoring/sample_submission.csv\n",
    "/kaggle/input/sf-dst-scoring/train.csv\n",
    "/kaggle/input/sf-dst-scoring/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используемые функции\n",
    "\n",
    "def show_roc_auc(y_test, y_probs):\n",
    "    \"\"\"Функция построения графика ROC AUC\"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_probs)\n",
    "    roc_auc = roc_auc_score(y_test, y_probs)\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], label='Baseline', linestyle='--')\n",
    "    plt.plot(fpr, tpr, label = 'Regression')\n",
    "    plt.title('Logistic Regression ROC AUC = %0.3f' % roc_auc)\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_confusion_matrix(lastmodel,X_test,y_test):\n",
    "    \"\"\"Функция построения матрицы ошибок\"\"\"\n",
    "    class_names = ['NonDefault', 'Default']\n",
    "    titles_options = [(\"Confusion matrix\", None)]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(lastmodel, X_test, y_test, \n",
    "                                     display_labels=class_names, \n",
    "                                     cmap=plt.cm.Blues, \n",
    "                                     normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def num_column_analysis(i):\n",
    "    \"\"\"Функция визуализации данных числовых признаков\"\"\"\n",
    "    display(pd.DataFrame(train[i].value_counts(normalize=True, sort=True)))\n",
    "    \n",
    "    sns.boxplot(x = 'default', y = i, data = train) # строим boxplot\n",
    "    plt.show()\n",
    "    \n",
    "    train[i].hist(bins = 100) # строим гистограмму\n",
    "    \n",
    "    \n",
    "def combining_types_car(row):\n",
    "    \"\"\"Функция объединения признаков car и car_type\"\"\"\n",
    "    result = row['car'] + row['car_type'] \n",
    "    return result\n",
    "# в итоге получаем: если 0, то машины нет, если 1 - то есть отечественная, если 2 - то есть иномарка\n",
    "\n",
    "\n",
    "def combining_types_adr(row):\n",
    "    \"\"\"Функция объединения признаков home_address и work_address\"\"\"\n",
    "    result = 10*row['home_address'] + row['work_address'] \n",
    "    return result\n",
    "# В итоге полуаем двузначное число, где первая цифра будет показывать признак home_address, вторая - work_address "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Загрузка и предварительный осмотр данных\n",
    "PATH_to_file = '/kaggle/input/sf-dst-scoring/'\n",
    "train = pd.read_csv(PATH_to_file + 'train.csv')\n",
    "test = pd.read_csv(PATH_to_file + 'test.csv')\n",
    "sample_submission = pd.read_csv(PATH_to_file + 'sample_submission.csv')\n",
    "# Для контроля зафиксируем размер тренировочного и тестового датасетов.\n",
    "print('Размер тренировочного датасета: ', train.shape,\n",
    "      'Размер тестового датасета: ', test.shape, \n",
    "      'Размер объединенного датасета: ', train.shape[0]+test.shape[0], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем тренировочные и тестовые данные в один датасет для того чтоб все монипуляции с признаками проводить\n",
    "# на обоих датасетах\n",
    "train['train'] = 1 # помечаем тренировочные\n",
    "test['train'] = 0 # помечаем тестовые\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расшифровка признаков\n",
    "#client_id - идентификатор клиента\n",
    "#education - уровень образования\n",
    "#sex - пол заемщика\n",
    "#age - возраст заемщика\n",
    "#car - флаг наличия автомобиля\n",
    "#car_type - флаг автомобиля иномарки\n",
    "#decline_app_cnt - количество отказанных прошлых заявок\n",
    "#good_work - флаг наличия “хорошей” работы\n",
    "#bki_request_cnt - количество запросов в БКИ\n",
    "#home_address - категоризатор домашнего адреса\n",
    "#work_address - категоризатор рабочего адреса\n",
    "#income - доход заемщика\n",
    "#foreign_passport - наличие загранпаспорта\n",
    "#sna - связь заемщика с клиентами банка\n",
    "#first_time - давность наличия информации о заемщике\n",
    "#score_bki - скоринговый балл по данным из БКИ\n",
    "#region_rating - рейтинг региона\n",
    "#app_date - дата подачи заявки\n",
    "#default - флаг дефолта по кредиту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Общая информация о полях\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проводим быстрый EDA c помощью pandas_profiling:\n",
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Из отчета видно что пропуски присутствуют только в колонке education. \n",
    "#Выборка по целевой переменной не сбалансирована. \n",
    "#Количество дефолтных клиентов в 6 раз больше чем не дефолтных. \n",
    "#По heatmap видно, что больше всего коррелируют между собой признаки: first_time и sna, work_address и home_address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Предварительная обработка данных для построения наивной модели\n",
    "\n",
    "# Начнем с того что избавимся от пропусков в колонке education.\n",
    "# Посмотрим распределение значений.\n",
    "df['education'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменим пропуски случайными значениями в том же соотношении, ACD пропускаем т.к. оно намного меньше 1%\n",
    "df.fillna('empty',inplace=True)\n",
    "df['education']=df['education'].apply(lambda x: np.random.choice(['SCH','GRD','UGR','PGR'],p=[0.53,0.32,0.13,0.02]) \n",
    "                                     if x=='empty' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем списки числовых, бинарных и категориальных переменных:\n",
    "# Признак app_day пока выкидываем\n",
    "\n",
    "# числовые\n",
    "num_cols = [\n",
    "    'age',\n",
    "    'decline_app_cnt',\n",
    "    'score_bki',\n",
    "    'bki_request_cnt',\n",
    "    'income',\n",
    "    ]\n",
    "\n",
    "# бинарные\n",
    "bin_cols = [\"sex\", \"car\", \"car_type\", \"good_work\", \"foreign_passport\"]\n",
    "\n",
    "# категориальные\n",
    "cat_cols = [\n",
    "    'education',\n",
    "    'region_rating',\n",
    "    'home_address',\n",
    "    'work_address',\n",
    "    'sna',\n",
    "    'first_time',\n",
    "    ]         \n",
    "# Для бинарных признаков используем LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for i in bin_cols:\n",
    "    df[i] = label_encoder.fit_transform(df[i])\n",
    "    \n",
    "df[bin_cols].sample(5) # проверим что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим датасет обратно на обучающую и тестовую часть\n",
    "train = df[df['train']==1].drop(['train'],axis=1)\n",
    "test = df[df['train']==0].drop(['train','default'],axis=1)\n",
    "# Проверим соответствие размеров датасетов исходным\n",
    "print('Размер тренировочного датасета: ', train.shape,\n",
    "      'Размер тестового датасета: ', test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем OneHot-кодирование категориальных признаков:\n",
    "X_cat = OneHotEncoder(sparse=False).fit_transform(train[cat_cols].values)\n",
    "# Объединяем числовые, бинарные и категориальные переменные в одно признаковое пространство\n",
    "X = np.hstack([train[num_cols], train[bin_cols].values,X_cat])\n",
    "Y = train['default'].to_numpy().astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Построим наивную моель\n",
    "\n",
    "# Обучаем модель:\n",
    "\n",
    "model_0 = LogisticRegression(solver='liblinear')\n",
    "model_0.fit(X_train, y_train)\n",
    "y_pred = model_0.predict(X_test)\n",
    "\n",
    "# Строим ROC AUC \n",
    "\n",
    "probs = model_0.predict_proba(X_test)\n",
    "probs = probs[:,1]\n",
    "show_roc_auc(y_test,probs)\n",
    "\n",
    "# Строим матрицу ошибок\n",
    "\n",
    "show_confusion_matrix(model_0,X_test,y_test)\n",
    "\n",
    "# Остальные метрики\n",
    "\n",
    "print('accuracy_score: {}'.format(np.round(accuracy_score(y_test, y_pred), 4)))\n",
    "print('f1_score: {}'.format(np.round(f1_score(y_test, y_pred), 4)))\n",
    "print('recall_score: {}'.format(np.round(recall_score(y_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Результат оказался посредственным. Значение ROC AUC 0.55. \n",
    "#По матрице ошибок видно что модель вообще не предсказала дефолтных клиетов. Зато теперь есть на что опираться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Дальнейшая обработка данных\n",
    "\n",
    "# В столбце app_date переводим дату в подходящий вид:\n",
    "df['app_date'] = pd.to_datetime(df['app_date'])\n",
    "\n",
    "# Посмотрим период наблюдений:\n",
    "display(df['app_date'].min())\n",
    "display(df['app_date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем новые признаки на основе даты:\n",
    "\n",
    "df['day'] = df.app_date.dt.day\n",
    "df['month'] = df.app_date.dt.month\n",
    "df['weekday'] = df.app_date.dt.weekday\n",
    "# Посчитаем количество дней до даты конца наблюдений\n",
    "df['days'] = (df.app_date.max() - df.app_date).dt.days\n",
    "# Избавляемся от уже не нужного столбца app_date\n",
    "df.drop(['app_date'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Еще раз создаем списки числовых, бинарных и категориальных переменных с учетом изменений:\n",
    "\n",
    "# числовые\n",
    "num_cols = [\n",
    "    'age',\n",
    "    'decline_app_cnt',\n",
    "    'score_bki',\n",
    "    'bki_request_cnt',\n",
    "    'income',\n",
    "    'day',\n",
    "    'month',\n",
    "    'weekday',\n",
    "    'days'\n",
    "    ]\n",
    "\n",
    "# бинарные\n",
    "bin_cols = [\"sex\", \"car\", \"car_type\", \"good_work\", \"foreign_passport\"]\n",
    "\n",
    "# категориальные\n",
    "cat_cols = [\n",
    "    'education',\n",
    "    'region_rating',\n",
    "    'home_address',\n",
    "    'work_address',\n",
    "    'sna',\n",
    "    'first_time',\n",
    "    ]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на корреляцию числовых признаков между собой\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.heatmap(df[num_cols].corr().abs(), vmin=0, vmax=1,\n",
    "            annot=True, fmt=\".2f\", cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Как видим из вновь добавленных признаков сильно коррелируют days и month. От какого-то надо избавляться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим также на значимость числовых переменных:\n",
    "\n",
    "temp = df[df['train'] == 1]\n",
    "imp_num = pd.Series(f_classif(temp[num_cols], temp['default'])[0], index = num_cols)\n",
    "imp_num.sort_values(inplace = True)\n",
    "imp_num.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Days находится выше, поэтому убираем month.\n",
    "#Day и weekday не оказывают значимого влияния на целевую переменную. Их тоже удаляем.\n",
    "\n",
    "df.drop(['month','day','weekday'],axis=1,inplace=True)\n",
    "# Также удалим их из нашего списка числовых признаков\n",
    "num_cols.remove('month')\n",
    "num_cols.remove('day')\n",
    "num_cols.remove('weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Еще раз пройдемся признакам и посмотрим на них внимательнее. Начнем с простого, биномаильных признаков.\n",
    "\n",
    "# Мы их уже перекодировали, так что посмотрим на их корреляцию\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.heatmap(df[bin_cols].corr().abs(), vmin=0, vmax=1,\n",
    "            annot=True, fmt=\".2f\", cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Явно бросается в глаза сильная корреляция признаков car и car_type. Попробуем эти два признака объединить в один.\n",
    "\n",
    "df['car'] = df.apply(lambda row: combining_types_car(row), axis=1)\n",
    "# Удаляем уже не нужный столбец car_type\n",
    "df.drop(['car_type'],axis=1,inplace=True)\n",
    "bin_cols.remove('car_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Переходим к категориальным признакам. Посмотрим на их корреляцию.\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.heatmap(df[cat_cols].corr().abs(), vmin=0, vmax=1,\n",
    "            annot=True, fmt=\".2f\", cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Здесь видна корреляция между пизнаками work_address и home_address. \n",
    "#Попробуем их также объединить в один признак. Между sna и first_time тоже не маленькая корреляция, \n",
    "#но думаю все же их оставить без изменения.\n",
    "\n",
    "df['address'] = df.apply(lambda row: combining_types_adr(row), axis=1)\n",
    "\n",
    "cat_cols.append('address')\n",
    "\n",
    "cat_cols.remove('home_address')\n",
    "df.drop(['home_address'], axis=1, inplace=True)\n",
    "\n",
    "cat_cols.remove('work_address')\n",
    "df.drop(['work_address'], axis=1, inplace=True)\n",
    "# Разделим категориальные признаки по столбцам\n",
    "df = pd.get_dummies(\n",
    "    df, columns=['education', 'region_rating', 'sna', 'first_time', 'address','sex', 'car', 'good_work', 'foreign_passport'], dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Остались только числовые признаки.\n",
    "\n",
    "# Разделим наш общий датасет обратно на тренировочный и тестовый, чтоб проводить изменения только в тренировочном.\n",
    "train = df[df['train']==1].drop(['train'],axis=1)\n",
    "test = df[df['train']==0].drop(['train','default'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим соответствие размеров датасетов исходным\n",
    "print('Размер тренировочного датасета: ', train.shape,\n",
    "      'Размер тестового датасета: ', test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Столбец age\n",
    "num_column_analysis('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выбросов нет, но распределение значений смещено в право. Прологарифмируем этот признак.\n",
    "\n",
    "train['age'] = np.log(train['age'] + 1)\n",
    "test['age'] = np.log(test['age'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Столбец decline_app_cnt\n",
    "num_column_analysis('decline_app_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Здесь уже есть выбросы, но они можно сказать единичны по сравнению со всем датасетом. \n",
    "#Больше значения 4 суммарное количество наблюдений не наберет и 1%. Поэтому все значения больше 4 заменим на 4.\n",
    "\n",
    "train['decline_app_cnt']=train['decline_app_cnt'].apply(lambda x: x if x<=4 else 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# столбец score_bki\n",
    "num_column_analysis('score_bki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Распределение нормальное. Выбросы хоть и есть, но думаю их оставить без изменений т.к. \n",
    "#их значения не сильно отличаются от остальных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Столбец bki_request_cnt\n",
    "num_column_analysis('bki_request_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тут тоже наблюдаем выбросы. Т.к. их суммарная доля после значения 9 очень мала (меньше 1%), \n",
    "#то все что больше 9 заменим на 9. Распределение здесь смещено в право, прологарифмируем этот признак.\n",
    "\n",
    "train['bki_request_cnt']=train['bki_request_cnt'].apply(lambda x: x if x<=9 else 9)\n",
    "train['bki_request_cnt'] = np.log(train['bki_request_cnt'] + 1)\n",
    "test['bki_request_cnt'] = np.log(test['bki_request_cnt'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Столбец income\n",
    "num_column_analysis('income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Здесь тоже наблюдаем много выбросов. Больше 200к получают малое количество клиентов. \n",
    "#Приравняем их доход к 200к. Также прологорифмируем этот признак чтоб привести его к более нормальному распределению.\n",
    "\n",
    "train['income']=train['income'].apply(lambda x: x if x<=200000 else 200000)\n",
    "train['income'] = np.log(train['income'] + 1)\n",
    "test['income'] = np.log(test['income'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Построение модели\n",
    "\n",
    "# Стандартизируем числовые признаки в обучающей и тестовой выборке\n",
    "scaler=StandardScaler().fit(train[num_cols])\n",
    "train_std=scaler.transform(train[num_cols])\n",
    "train[num_cols]=train_std\n",
    "test_std=scaler.transform(test[num_cols])\n",
    "test[num_cols]=test_std\n",
    "# Обновим общий датасет\n",
    "train['train'] = 1 # помечаем тренировочные\n",
    "test['train'] = 0 # помечаем тестовые\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# Делим выборку на обучающую и тестовую\n",
    "X = train[list(set(train.columns) - set(['default','client_id']))].values\n",
    "Y = train['default'].to_numpy().astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель:\n",
    "\n",
    "model_1 = LogisticRegression(solver='liblinear')\n",
    "model_1.fit(X_train, y_train)\n",
    "y_pred = model_1.predict(X_test)\n",
    "\n",
    "# Строим ROC AUC \n",
    "\n",
    "probs = model_1.predict_proba(X_test)\n",
    "probs = probs[:,1]\n",
    "show_roc_auc(y_test,probs)\n",
    "\n",
    "# Строим матрицу ошибок\n",
    "\n",
    "show_confusion_matrix(model_1,X_test,y_test)\n",
    "\n",
    "# Остальные метрики\n",
    "\n",
    "print('accuracy_score: {}'.format(np.round(accuracy_score(y_test, y_pred), 4)))\n",
    "print('f1_score: {}'.format(np.round(f1_score(y_test, y_pred), 4)))\n",
    "print('recall_score: {}'.format(np.round(recall_score(y_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Уже лучше чем наивная модель. ROC AUC = 0.741. Модель хоть как-то начала определять дефолтных клиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Модель 1 + oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем простейший oversampling посредством дублирования строк с дефолтом:\n",
    "\n",
    "zeros = train[train['default'] == 0]\n",
    "ones = train[train['default'] == 1]\n",
    "default_new = int(len(zeros) / len(ones))\n",
    "for i in range(default_new):\n",
    "    train1 = train.append(ones).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим выборку на обучающую и тестовую\n",
    "X = train1[list(set(train.columns) - set(['default','client_id']))].values\n",
    "Y = train1['default'].to_numpy().astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель:\n",
    "\n",
    "model_2 = LogisticRegression(solver='liblinear')\n",
    "model_2.fit(X_train, y_train)\n",
    "y_pred = model_2.predict(X_test)\n",
    "\n",
    "# Строим ROC AUC \n",
    "\n",
    "probs = model_2.predict_proba(X_test)\n",
    "probs = probs[:,1]\n",
    "show_roc_auc(y_test,probs)\n",
    "\n",
    "# Строим матрицу ошибок\n",
    "\n",
    "show_confusion_matrix(model_2,X_test,y_test)\n",
    "\n",
    "# Остальные метрики\n",
    "\n",
    "print('accuracy_score: {}'.format(np.round(accuracy_score(y_test, y_pred), 4)))\n",
    "print('f1_score: {}'.format(np.round(f1_score(y_test, y_pred), 4)))\n",
    "print('recall_score: {}'.format(np.round(recall_score(y_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Результат стал хуже. Площадь под кривой ROC AUC уменьшилась. \n",
    "#Количество ложно предсказанных не дефолтных клиентов тоже выросло."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Модель 1 + полиноминальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим новые признаки, через комбинацию\n",
    "data=df.copy()\n",
    "poly = PolynomialFeatures(2, include_bias=False)\n",
    "poly_data = poly.fit_transform(data[num_cols])[:, len(num_cols):]\n",
    "poly_cols = poly.get_feature_names()[len(num_cols):]\n",
    "poly_df = pd.DataFrame(poly_data, columns=poly_cols)\n",
    "data = data.join(poly_df,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем датасет\n",
    "train_p = data[data['train']==1].drop(['train'],axis=1)\n",
    "test_p = data[data['train']==0].drop(['train','default'],axis=1)\n",
    "# Делим выборку на обучающую и тестовую\n",
    "X = train_p[list(set(train_p.columns) - set(['default','client_id']))].values\n",
    "Y = train_p['default'].to_numpy().astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель:\n",
    "\n",
    "model_3 = LogisticRegression(solver='liblinear')\n",
    "model_3.fit(X_train, y_train)\n",
    "y_pred = model_3.predict(X_test)\n",
    "\n",
    "# Строим ROC AUC \n",
    "\n",
    "probs = model_3.predict_proba(X_test)\n",
    "probs = probs[:,1]\n",
    "show_roc_auc(y_test,probs)\n",
    "\n",
    "# Строим матрицу ошибок\n",
    "\n",
    "show_confusion_matrix(model_3,X_test,y_test)\n",
    "\n",
    "# Остальные метрики\n",
    "\n",
    "print('accuracy_score: {}'.format(np.round(accuracy_score(y_test, y_pred), 4)))\n",
    "print('f1_score: {}'.format(np.round(f1_score(y_test, y_pred), 4)))\n",
    "print('recall_score: {}'.format(np.round(recall_score(y_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Площадь под кривой немного выросла. Матрица ошибок показывает примерно тот же результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Модель 1 + полиноминальные признаки + гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим выборку на обучающую и тестовую\n",
    "X = train_p[list(set(train_p.columns) - set(['default','client_id']))].values\n",
    "Y = train_p['default'].to_numpy().astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим ограничения для параметра регуляризации\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "penalty = ['l1','l2']\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "model = LogisticRegression(solver = 'liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "clf = GridSearchCV(model, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Лучший penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Лучшее C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель:\n",
    "\n",
    "model_finish = LogisticRegression(penalty='l1', C=1.0, solver='liblinear')\n",
    "model_finish.fit(X_train, y_train)\n",
    "y_pred = model_finish.predict(X_test)\n",
    "\n",
    "# Строим ROC AUC \n",
    "\n",
    "probs = model_finish.predict_proba(X_test)\n",
    "probs = probs[:,1]\n",
    "show_roc_auc(y_test,probs)\n",
    "\n",
    "# Строим матрицу ошибок\n",
    "\n",
    "show_confusion_matrix(model_finish,X_test,y_test)\n",
    "\n",
    "# Остальные метрики\n",
    "\n",
    "print('accuracy_score: {}'.format(np.round(accuracy_score(y_test, y_pred), 4)))\n",
    "print('f1_score: {}'.format(np.round(f1_score(y_test, y_pred), 4)))\n",
    "print('recall_score: {}'.format(np.round(recall_score(y_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#И даже с гиперпараметрами результат как-то не поменялся( \n",
    "#Модель так и продолжает предсказывать большое количество ложно не дефолтных клиентов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Подготовка данных для соревнования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_fin = test_p[list(set(test_p.columns) - set(['default','client_id']))].values\n",
    "\n",
    "y_probs = model_finish.predict_proba(X_test_fin)[:,1]\n",
    "\n",
    "test_p['default'] = y_probs\n",
    "submission = test_p[['client_id','default']]\n",
    "display(submission.sample(10))\n",
    "display(submission.shape)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
